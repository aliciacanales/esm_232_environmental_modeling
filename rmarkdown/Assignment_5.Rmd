---
title: "Assignment_5"
author: "Alicia Canales & Zoe Zhou"
date: "`r Sys.Date()`"
output: html_document
code_folding: 'hide'
---

```{r setup, echo = TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(sensitivity)
library(tidyverse)
library(here)
library(purrr)
library(ggpubr)
```

### Reading and cleaning data for summer months
```{r}

## metric is high stream flow
sager = read.table(here('data', 'sager.txt'), header = TRUE)
head(sager)

## add date
sager = sager %>% 
  mutate(date = paste(day,month,year, sep="/"))

sager$date = as.Date(sager$date,"%d/%m/%Y")

## initial plot
sager_clean = sager %>% 
  pivot_longer(cols=c("model","obs"), names_to="source",
                                  values_to="flow") 

## subsetting only annual summer streamflow: june - august
annual_summer_flow <- sager_clean %>% 
  group_by(year, month, source) %>% 
  filter(month %in% c(6:8)) %>% 
  summarize(flow = sum(flow))


## plot of annual summer flow 
ggplot(annual_summer_flow, aes(year, flow, col = source, linetype = source)) +
  geom_line() +
  labs(x = 'Year', y = 'Annual Summer Streamflow') +
  scale_color_manual(values = c('blue', 'green4')) +
  theme_minimal()

```


### Developing a Combined Metric
```{r}
## performance metric using 
source('../functions/compute_low_flow.R')

## performance using compute low flow function
perf <- compute_low_flow(m=sager$model,o=sager$obs, month=sager$month, day=sager$day, year=sager$year, low_flow_months = c(6:8))

## making performance into a data frame
perf = as.data.frame((perf))

perf
```

### Split sample calibration
```{r}
## reading in data
source("../functions/compute_low_flow.R") 
msage = read.table("../Data/sagerm.txt", header=T)

## saving the number of simulations
number_sim = ncol(msage)

## making names for each simulation
snames = sprintf("S%d",seq(from = 1, to = number_sim))

## adding names to the columns
colnames(msage) = snames

## adding the dates to this df
msage$date = sager$date
msage$month = sager$month
msage$year = sager$year
msage$day = sager$day

## adding on the observed
msage = left_join(msage, sager[,c("obs","date")], by=c("date"))
head(msage)

```

```{r warning=FALSE, message=FALSE}
## subsetting for the split sample
subset_msage = subset(msage, year < 1985)

## running performance on all parameter sets
split_perf = subset_msage %>% 
  select(-date, -month, -day, -year, -obs ) %>%
  map_df(compute_low_flow, o = subset_msage$obs, month = subset_msage$month, day = subset_msage$day, year = subset_msage$year)

## adding names to simulations
split_perf$sim = snames
head(split_perf)
summary(split_perf)
```
```{r}
# select best and worst parameter sets based on the combined metric
best = split_perf[which.max(split_perf$combined),]
worst = split_perf[which.min(split_perf$combined),]
best
# compare best and worst parameter set performance
msage_pre = subset(msage, year < 1985)

# plot for streamflow 
ggplot(msage_pre, aes(date, msage_pre[, worst$sim])) + geom_line(, linetype = "dashed") +
  geom_line(aes(date, msage_pre[, best$sim]), col = "darkgrey") +
  geom_line(aes(date, obs), col = "brown" ) 

```
```{r}
# compare how best parameters perform for pre and post calibration focusing on August streamflow
# calibration period
compare_best = msage %>% select(best$sim, worst$sim, date, obs, month, day, year)
compare_best_pre = subset(compare_best, year < 1985)
compare_best_my = compare_best_pre %>% select(-c(day,date)) %>% group_by(month, year) %>% 
  summarize(across(everything(), mean))
compare_myl = compare_best_my %>% pivot_longer(cols=!c(month,year), names_to="sim", values_to="flow")
compare_myl %>% subset(month==8) %>% ggplot(aes(sim,flow ))+geom_boxplot()

#validation period
compare_best_post = subset(compare_best, year > 1985)
compare_best_post_my = compare_best_post %>% select(-c(day,date)) %>% group_by(month, year) %>% 
  summarize(across(everything(), mean))
compare_post_myl = compare_best_post_my %>% pivot_longer(cols=!c(month,year), names_to="sim", values_to="flow")
compare_post_myl %>% subset(month==8) %>% ggplot(aes(sim,flow ))+geom_boxplot()

```

### Discussion 
#### We combined 4 metrics to calculate our model's performance score: annual_min_err, annual_min_cor, low_months_err, and low_months_cor. Low months period includes June to August. The minimum error metrics are focused on the minimum values observed annually and in low-flow months, possibly reflecting the model's accuracy in predicting extreme low events or the smallest values within each year. We also given heavier weight on error and correlation in the low-flow months because we identified June, July and August to be a critical period for salmon habitat loss. 
#### Our model performed well within the calibration period with a combined performance of 0.89 out of 1. Our best parameter set also outscores the worst parameter set in validation period. 
